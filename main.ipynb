import numpy as np
import pandas as pd

movies=pd.read_csv('tmdb_5000_movies.csv')
credits=pd.read_csv('tmdb_5000_credits.csv')

movies.head(1)

credits.head(1)['crew']

movies=movies.merge(credits,on='title') # merging two data frames into one data frame

movies.head(1)

#Cloums to keep for making tags
#genres
#id for posters
#keywords
#title
#overview
#cast
#crew
movies=movies[['movie_id','title','overview','genres','keywords','cast','crew']] #keeping only these columns int the dataframe.

movies.head()

movies.isnull().sum() #telling that overview columnn has 3 null values(missing data)

movies.dropna(inplace=True) #removing 3 movies whose overview data was missing.
movies.isnull().sum()

movies.duplicated().sum() #telling that no duplicate row

movies.iloc[0].genres #see genre of movies is in very weird format(list of dictionaries)
#we want it to be in this format --> ['Action','Adventure','FFantasy','SciFi']

import ast #this is used to get dictionary from a string having dictionary inside
d=ast.literal_eval('[{"id": 28, "name": "Action"}, {"id": 12, "name": "Adventure"}, {"id": 14, "name": "Fantasy"}, {"id": 878, "name": "Science Fiction"}]')
print(d)

def convert(obj):
    L=[]
    for i in ast.literal_eval(obj):
        L.append(i['name'])
    return L
'''
OR

def convert(obj):
    L=[]
    for i in st.literal_eval(obj):
        L.append(i['name'])
    return L
x=convert(d)
print(x)
'''

movies['genres']=movies['genres'].apply(convert) #getting us a list of all the genres for every movie.

movies['keywords']=movies['keywords'].apply(convert) #getting us a list of all the keywords for every movie.

#movies['cast'][0] #now we will extract the names of cast from 1st three dictionaries only because these are the main actors in the movie.

def convert3(obj):
    L=[]
    c=0
    for i in ast.literal_eval(obj):
        if c!=3:
            L.append(i['name'])
            c+=1
        else:
            break
    return L

movies['cast']=movies['cast'].apply(convert3)

movies.head(1)

#movies['crew'][0]

def fetch_director(obj):
    L=[]
    for i in ast.literal_eval(obj):
        if i['job']=='Director':
            L.append(i['name'])
            break
    return L
    

movies['crew']=movies['crew'].apply(fetch_director)

movies.head()

movies['overview'][0]  #it is in the form of a string so we will convert in into a list

movies['overview'].apply(lambda x:x.split())

movies['overview']=movies['overview'].apply(lambda x:x.split())

movies.head()

#very important
#we will make 'Sam Worthington' --> 'SamWorthinton' (space will be removed)
#this is done because in case of 'Sam Worthinton' two tag will be created and for 'SamWorthinton' only one tag will be created.
#we also have a person named Sam Mendes, here also two tags will be created.
#So,here our model will confuse that which 'Sam' it should refer to and eventually make make wrong reccommendations.

movies['genres']=movies['genres'].apply(lambda x:[i.replace(" ","") for i in x]) #space will be removed in the generes.eg. 'Science Fiction' --> 'ScienceFiction'.
movies['keywords']=movies['keywords'].apply(lambda x:[i.replace(" ","") for i in x])
movies['cast']=movies['cast'].apply(lambda x:[i.replace(" ","") for i in x])
movies['crew']=movies['crew'].apply(lambda x:[i.replace(" ","") for i in x])

movies.head()

#adding generes,keywords,cast,crew into one single column named tag
movies['tags']=movies['overview']+movies['genres']+movies['keywords']+movies['cast']+movies['crew']

movies.head()

new_df=movies[['movie_id','title','tags']] #creted a new data frame having only movie_id,title and tags columns.

new_df.head()

new_df['tags']=new_df['tags'].apply(lambda x:" ".join(x)) #joined all the content of tags with a space.

new_df['tags'][0]

new_df.head()

#STEMMIMG - A technique such that
#['loved','love','loving'] --> ['love','love','love']

import nltk #required for the stemming of data , it's a very famous natural language processing library.

from nltk.stem.porter import PorterStemmer
ps=PorterStemmer()

def stem(text):
    y=[]
    for i in text.split():
        y.append(ps.stem(i))
    return " ".join(y)

new_df['tags']=new_df['tags'].apply(stem)

new_df['tags']=new_df['tags'].apply(lambda x:x.lower())

new_df['tags'][0]

new_df['tags'][1] 

from sklearn.feature_extraction.text import CountVectorizer
cv=CountVectorizer(max_features=5000,stop_words='english')

vectors=cv.fit_transform(new_df['tags']).toarray() #by default count vectorizer return a scipy sparks matrix,so we will convert it into a numpy array.

vectors[0]

cv.get_feature_names() #gives list of all 5000 words in the corpus. Corpus is the bigger string that is formed after adding all the tags.

#as the dimentionality of the data increses, the euclidian distance fails.
from sklearn.metrics.pairwise import cosine_similarity #we will use cosine distance to find the angle between any two vectors in the 5000 dimentional space

similarity=cosine_similarity(vectors) #it find distance of every movie with all other movies i.e 4806*4806 distances in this form --> [[1...x],[2....x],[1,2....x]......x] 

similarity #distance of every movie with all other movies i.e 4806*4806 distances

similarity[0] #distance of first movie with all other movies.
#diagonally all 1 as, similarity of a movie with itself is always 1.

list(enumerate(similarity[0])) #so that we do not loose the movie after sorting,as it will create a id for every movie
sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1]) #this will sort the movies based on 2nd number i.e 1.00000000000002
sorted(list(enumerate(similarity[0])),reverse=True,key=lambda x:x[1])[1:6] #first 6 movies ,most relatable

def reccomend(movie):
    movie_index=new_df[new_df['title']==movie].index[0]
    distances=similarity[movie_index]
    movies_list=sorted(list(enumerate(distances)),reverse=True,key=lambda x:x[1])[1:6]
    
    for i in movies_list:
        print(new_df.iloc[i[0]].title)
        #print(i[0])
    

new_df[new_df['title']=='Batman Begins'].index[0] #this is how we get index of any movie.
new_df.iloc[1216].title #gives movie name from index number.

reccomend('Batman Begins')#most reccomendable movies for 'Avatar '

import pickle #to send the movies to the website code

pickle.dump(new_df,open('movies.pkl','wb')) #wb-->write binary mode

new_df['title'].values

pickle.dump(similarity,open('similarity.pkl','wb')) #sending similarity file



